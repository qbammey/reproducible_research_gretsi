{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Reproducible Research: From Code to Career\"\n",
        "subtitle: \"How to save time, build trust, and maximize your impact\"\n",
        "author: \"Adrien Krähenbühl (ICube, Université de Strasbourg), Quentin Bammey (Image and Visual Representation Lab, École Polytechnique Fédérale de Lausanne), Gabriele Facciolo (Centre Borelli, ENS Paris-Saclay; Institut Universitaire de France)\"\n",
        "lightbox: true\n",
        "scrollable: true\n",
        "format: \n",
        "  revealjs:\n",
        "    theme: style/theme.scss\n",
        "    embed-resources: false\n",
        "    view-distance: 800\n",
        "    mermaid: {}\n",
        "    callout-appearance: simple\n",
        "    slide-number: c\n",
        "    menu:\n",
        "      side: left\n",
        "      width: wide\n",
        "      numbers: true\n",
        "---\n",
        "\n",
        "## Reproducible Research: From Code to Career {.title-slide}:\n",
        "\n",
        ":::: {.columns}\n",
        ":::{.column width=65%}\n",
        "### How to save time, build trust, and maximize your impact\n",
        "\n",
        "**Quentin Bammey (EPFL, IVRL), Gabriele Facciolo (ENS Paris-Saclay, Centre Borelli), Adrien Krähenbühl (Unistra, ICube)**\n",
        "\n",
        ":::\n",
        "::: {.column width=35%}\n",
        "![](images/qrcode.png)\n",
        "<small>[Slides: bammey.com/gretsi](https://bammey.com/gretsi/)</small>\n",
        "<small>[Code to the slides and demo: github.com/qbammey/reproducible_research_gretsi](https://github.com/qbammey/reproducible_research_gretsi)</small>\n",
        ":::\n",
        "::::\n",
        "\n",
        "::: footer\n",
        "![](images/epfl.svg) ![](images/ivrl.png) ![](images/ens.png) ![](images/cgb.png) ![](images/unistra.png) ![](images/icube.png)\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "## A new SOTA has been established!\n",
        "\n",
        "![](images/breakthrough.png)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## The Researcher's Journey: A Case Study\n",
        "\n",
        "Let's walk through a realistic attempt to run the code from a newly published paper.\n",
        "\n",
        "::: {.r-stack}\n",
        "\n",
        "::: {.fragment}\n",
        "````{=html}\n",
        "<div class=\"panel-code\">\n",
        "<pre><code>$ python train.py\n",
        "\n",
        "Traceback (most recent call last):\n",
        "  File \"train.py\", line 5, in <module>\n",
        "    from fancy_layers import CustomAttentionBlock\n",
        "<span style=\"color: #d83939; font-weight: bold;\">ModuleNotFoundError: No module named 'fancy_layers'</span></code></pre>\n",
        "</div>\n",
        "````\n",
        ":::\n",
        "\n",
        "::: {.fragment}\n",
        "````{=html}\n",
        "<div class=\"panel-code\">\n",
        "<pre><code>$ python train.py --fix_dependencies\n",
        "\n",
        "Running feature extraction...\n",
        "  File \"train.py\", line 73, in <module>\n",
        "    features = extract_features(data)\n",
        "  File \"/app/utils/features.py\", line 31, in extract_features\n",
        "    fd, hog_image = hog(image, orientations=8, visualise=True)\n",
        "<span style=\"color: #d83939; font-weight: bold;\">TypeError: hog() got an unexpected keyword argument 'visualise'</span></code></pre>\n",
        "</div>\n",
        "````\n",
        ":::\n",
        "\n",
        "::: {.fragment}\n",
        "````{=html}\n",
        "<div class=\"panel-code\">\n",
        "<pre><code>$ python train.py --fix_dependencies --legacy_skimage --fix_paths\n",
        "\n",
        "Model training started...\n",
        "Data loaded successfully.\n",
        "Epoch 1/100\n",
        "[...]\n",
        "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\", line 2854, in linear\n",
        "    return torch.addmm(bias, input, weight.t())\n",
        "<span style=\"color: #d83939; font-weight: bold;\">RuntimeError: CUDA out of memory. Tried to allocate 12.58 GiB (GPU 0; 15.90 GiB total capacity)</span></code></pre>\n",
        "</div>\n",
        "````\n",
        ":::\n",
        "\n",
        "::: {.fragment}\n",
        "````{=html}\n",
        "<div class=\"panel-code\">\n",
        "<pre><code>$ python train.py --fix_dependencies --legacy_skimage\n",
        "\n",
        "Model training started...\n",
        "Loading data...\n",
        "Traceback (most recent call last):\n",
        "  File \"train.py\", line 150, in <module>\n",
        "    dataset = H5Dataset(config['dataset_path'])\n",
        "  File \"/app/utils/data.py\", line 17, in __init__\n",
        "    self.h5_file = h5py.File(path, 'r')\n",
        "<span style=\"color: #d83939; font-weight: bold;\">FileNotFoundError: [Errno 2] No such file or directory: '/home/clara/data/grestsi_dataset/train_set.h5'</span></code></pre>\n",
        "</div>\n",
        "````\n",
        ":::\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Our Collective Technical Debt\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/c4jt321.png){fig-align=\"center\" width=\"400\"}\n",
        "\n",
        "\n",
        "* The magic parameter `alpha = 0.87` (source: unknown).\n",
        "* \"It worked yesterday, I swear.\"\n",
        "* `requirements.txt`: `numpy`, `pytorch` (Reality: 58 hidden packages).\n",
        "* The true hero of every project: `Final_Final_v2_really_final.ipynb`.\n",
        "\n",
        "::: notes\n",
        "And let's be honest, we're not just victims here—we're also the culprits. We rush to meet deadlines. We tell ourselves we'll clean up the code and document it later. We create this technical debt. But that debt has consequences, not just for others, but for our own future success. To make this concrete, let me tell you a quick story.\n",
        ":::\n",
        "\n",
        "\n",
        "## A Tale of Two Researchers\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "### Clara, The Sprinter\n",
        "\n",
        "::: {.fragment}\n",
        "![](images/clara.png){fig-align=\"center\" width=\"250\"}\n",
        "\n",
        "- **Focus:** Get the result. Publish the paper. Move on.\n",
        "- **Code:** \"It works on my machine.\" Pushed to GitHub and forgotten.\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "### Maria, The Builder\n",
        "\n",
        "::: {.fragment}\n",
        "![](images/maria.png){fig-align=\"center\" width=\"250\"}\n",
        "\n",
        "- **Focus:** Get the result *and* make it usable.\n",
        "- **Code:** Packaged with a clean, well-described, usable implementation.\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "::: notes\n",
        "Meet Clara and Maria. Both are brilliant researchers. They both developed fantastic new methods and got their papers accepted right here at GRETSI. They had similar results, but they had very different philosophies about their code. Let's fast forward one year and see how their choices played out.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## One Year Later: Clara's Path\n",
        "### The Sprinter's Journey\n",
        "\n",
        "```{mermaid}\n",
        "flowchart TD\n",
        "    A[Paper Published] --> B{Industry Contact};\n",
        "    B --> C[2 weeks later: code fails];\n",
        "    C --> D[Opportunity lost];\n",
        "    A --> E{Journal Extension};\n",
        "    E --> F[3 Weeks to reproduce own results];\n",
        "    F --> G[Time lost];\n",
        "    A --> H{GitHub Repo};\n",
        "    H --> I[3 “Doesn't work” issues];\n",
        "    I --> J[Impact Limited];\n",
        "    classDef default color:#ddddee, fill:#1d1d2a, border:#ddddee;\n",
        "```\n",
        "\n",
        "::: notes\n",
        "Clara sprinted to the deadline. But her 'finished' paper was built on a fragile foundation. When a potential collaborator or employer came knocking, the door was effectively closed. Even worse, her most important collaborator—'Future Clara'—was stuck, wasting weeks rebuilding what she had already done. The initial splash of the publication quickly faded.\n",
        ":::\n",
        "\n",
        "\n",
        "## One Year Later: Maria's Path\n",
        "### The Builder's Journey\n",
        "\n",
        "```{mermaid}\n",
        "flowchart TD\n",
        "    A[Paper Published] --> B{Industry Contact};\n",
        "    B --> C[Demo & Container work instantly];\n",
        "    C --> D[Collaboration Gained];\n",
        "    A --> E{Community};\n",
        "    E --> F[Code used as baseline];\n",
        "    F --> G[Reputation Built];\n",
        "    A --> H{GitHub Repo};\n",
        "    H --> I[150 Stars, Pull Requests];\n",
        "    I --> J[Impact Multiplied];\n",
        "    classDef default color:#ddddee, fill:#1d1d2a, border:#ddddee;\n",
        "```\n",
        "\n",
        "::: notes\n",
        "Maria, on the other hand, invested a little extra time—maybe 10%—to build something robust. This small, upfront investment acted as an impact multiplier. Her work wasn't just *read*; it was *used*, *verified*, and *built upon*. She didn't just publish a paper; she delivered a reliable tool to the community, and the community rewarded her for it.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## The Core Principle\n",
        "\n",
        "::: {.fragment .fade-in-then-semi-out}\n",
        "$$Impact = Performance \\times Usability$$\n",
        ":::\n",
        "\n",
        "::: {.fragment}\n",
        "A brilliant result that no one can use has an impact of zero.\n",
        ":::\n",
        "\n",
        "::: {.fragment}\n",
        "**Reproducibility turns your paper from a claim into a contribution.**\n",
        ":::\n",
        "\n",
        "::: notes\n",
        "The difference between Clara and Maria comes down to this single principle. For too long, our community has been obsessed with the 'Performance' term. But the true, lasting impact of our work is a product of its performance *and* its usability. The story of Clara and Maria shows us that reproducibility isn't just an ethical nice-to-have; it's a core driver of scientific and career success.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Our Goal Today: The Builder's Toolkit\n",
        "\n",
        "1.  **The Framework:** Define the pillars of reproducibility.\n",
        "2.  **The Toolbox:** Go from a messy script to a clean, usable and understandable implementation.\n",
        "3.  **The Payoff:** Create and deploy an interactive web demo of your code in minutes.\n",
        "\n",
        "::: {.fragment}\n",
        "### You will leave here with a concrete plan to become a 'Builder'.\n",
        ":::\n",
        "\n",
        "::: notes\n",
        "The good news is that everything Maria did is accessible to all of us. It doesn't require being a software engineering expert. It just requires knowing a few key tools and a simple workflow. That is our mission for the rest of this session. We'll establish a clear framework, I'll walk you through the essential tools in a live demo, and we'll see the payoff by building an interactive demo. By the end, you'll have a practical plan to ensure your next great idea has the impact it deserves. Let's get started.\n",
        ":::\n",
        "\n",
        "# The pillars of reproducibility {visibility=\"hidden\"}\n",
        "\n",
        "## The pillars of reproducibility\n",
        "\n",
        "To understand these concepts, let's run a simple experiment: can a small neural network tell the difference between a T-shirt and a pair of Trousers?"
      ],
      "id": "4ea36199"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Function to run one complete experiment\n",
        "def run_experiment(seed):\n",
        "    # Load the Fashion-MNIST dataset\n",
        "    X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False, parser='liac-arff')\n",
        "\n",
        "    # Filter for two classes: 'T-shirt' (0) and 'Trouser' (1)\n",
        "    tshirt_trouser_indices = np.where((y == '0') | (y == '1'))\n",
        "    X_subset, y_subset = X[tshirt_trouser_indices], y[tshirt_trouser_indices]\n",
        "    \n",
        "    # Split the data with a fixed random_state\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_subset, y_subset, test_size=0.2, random_state=seed\n",
        "    )\n",
        "\n",
        "    # Define and train a model with a fixed random_state\n",
        "    model = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, random_state=seed)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate and return the accuracy\n",
        "    predictions = model.predict(X_test)\n",
        "    return accuracy_score(y_test, predictions)"
      ],
      "id": "11aa4a3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pillar 1: Repeatability\n",
        "\n",
        "::: {.callout-note}\n",
        "#### Repeatability: \"Can I get the exact same result twice?\"\n",
        "The key to this is to **record and describe** the procedure used to run the code, and **fix the random state**\n",
        ":::\n",
        "\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}"
      ],
      "id": "9f2aef01"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run the experiment twice with the same seed\n",
        "seed = 42\n",
        "accuracy_run_1 = run_experiment(seed)\n",
        "accuracy_run_2 = run_experiment(seed)\n",
        "\n",
        "print(f\"Seed used for both runs: {seed}\")\n",
        "print(f\"Accuracy of Run 1: {accuracy_run_1:.4f}\")\n",
        "print(f\"Accuracy of Run 2: {accuracy_run_2:.4f}\")"
      ],
      "id": "895ad1c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}"
      ],
      "id": "3e44998d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig = go.Figure([\n",
        "    go.Bar(name='Run 1', x=['Accuracy'], y=[accuracy_run_1]),\n",
        "    go.Bar(name='Run 2', x=['Accuracy'], y=[accuracy_run_2])\n",
        "])\n",
        "fig.update_layout(\n",
        "    title='Repeatability: Two Runs, Same Seed',\n",
        "    yaxis_title='Accuracy',\n",
        "    yaxis=dict(range=[0.95, 1.0]),\n",
        "    barmode='group',\n",
        "    legend_title='Experiment Run',\n",
        "    template='plotly_dark'\n",
        ")\n",
        "fig.show()"
      ],
      "id": "14539336",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perfect match. This is **repeatability**.\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Pillar 2: Reproducibility\n",
        "\n",
        "::: {.callout-note}\n",
        "#### Reproducibility: \"Does my finding hold if we change the random seed?\"\n",
        "The goal is to reach the same scientific conclusion, even if the numbers aren't identical.\n",
        ":::\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}"
      ],
      "id": "a43ea971"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "# We re-use the run_experiment function from the previous slide.\n",
        "\n",
        "# Run the experiment 5 times with different seeds\n",
        "seeds = [0, 42, 101, 1337, 2025]\n",
        "accuracies = []\n",
        "for seed in seeds:\n",
        "    acc = run_experiment(seed)\n",
        "    accuracies.append(acc)\n",
        "    print(f\"Seed: {seed:<4} -> Accuracy: {acc:.4f}\")"
      ],
      "id": "23b3ac9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::: {.column width=\"50%\"}"
      ],
      "id": "600428e5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig = go.Figure(data=go.Box(\n",
        "    y=accuracies,\n",
        "    name='Model Accuracy',\n",
        "    boxpoints='all',\n",
        "    jitter=0.3,\n",
        "    pointpos=-1.8\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Reproducibility: Accuracy Across 5 Seeds',\n",
        "    yaxis_title='Accuracy',\n",
        "    yaxis=dict(range=[0.95, 1.0]),\n",
        "    template='plotly_dark'\n",
        ")\n",
        "fig.show()"
      ],
      "id": "5bed0d35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy remains similar: this is reproducibility.\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "### Pillar 3: Replicability\n",
        "\n",
        "::: {.callout-note}\n",
        "#### Replicability: \"Is my finding a real phenomenon, or a quirk of my dataset?\"\n",
        "The gold standard: testing if a scientific discovery holds up under a new, independent study.\n",
        ":::\n",
        "\n",
        "Let's challenge our finding by applying the *same model* to a new task: telling 'Sandals' from 'Ankle Boots'.\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}"
      ],
      "id": "5910516b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "def run_replication_experiment(seed, class1_label, class2_label):\n",
        "    # Load the same Fashion-MNIST dataset\n",
        "    X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False, parser='liac-arff')\n",
        "\n",
        "    # Filter for two NEW classes: 'Sandal' (5) and 'Ankle Boot' (9)\n",
        "    sandal_boot_indices = np.where((y == class1_label) | (y == class2_label))\n",
        "    X_subset, y_subset = X[sandal_boot_indices], y[sandal_boot_indices]\n",
        "    \n",
        "    # Split, train, and evaluate using the same model architecture\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_subset, y_subset, test_size=0.2, random_state=seed\n",
        "    )\n",
        "    model = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, random_state=seed)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    return accuracy_score(model.predict(X_test), y_test)\n",
        "# Run the replication experiment\n",
        "accuracy_replication = run_replication_experiment(seed=42, class1_label='5', class2_label='9')\n",
        "\n",
        "# For comparison, let's use our first result\n",
        "accuracy_original = accuracy_run_1 \n",
        " \n",
        "#print(f\"Original Task (T-shirt vs Trouser) Accuracy: {accuracy_original:.4f}\")\n",
        "print(f\"Replication Task (Sandal vs Boot) Accuracy: {accuracy_replication:.4f}\")"
      ],
      "id": "e3a21db2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}"
      ],
      "id": "f1fcdc97"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig = go.Figure([\n",
        "    go.Bar(name='Original Study', x=['T-shirt vs Trouser'], y=[accuracy_original]),\n",
        "    go.Bar(name='Replication Study', x=['Sandal vs Ankle Boot'], y=[accuracy_replication])\n",
        "])\n",
        "fig.update_layout(\n",
        "    title='Replicability: Testing the Finding on New Data',\n",
        "    yaxis_title='Accuracy',\n",
        "    yaxis=dict(range=[0.9, 1.0]),\n",
        "    template='plotly_dark'\n",
        ")\n",
        "fig.show()"
      ],
      "id": "2f6e6cb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The core discovery holds up under new scrutiny. This is the gold standard: **replicability**.\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Beyond Running Code: Algorithmic Reproducibility\n",
        "\n",
        "::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "![The article as a blueprint](images/blueprint.png)\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "![Does the blueprint precisely describe what we implemented?](images/blueprint_result.png)\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "> So far, we've focused on re-running existing code. Now, we ask the deeper questions:\n",
        ">\n",
        "> 1.  If your code vanished, could someone rebuild it from your paper alone? (**Longevity**)\n",
        "> 2.  Does your code contain \"secret features\" not shown in the blueprint? (**Validation**)\n",
        "\n",
        "---\n",
        "\n",
        "## A Rogues' Gallery of Vague Papers {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"25%\"}\n",
        "![The Magic Number](images/mugshot_number.png){fig-align=\"center\" height=\"250\"}\n",
        "\n",
        "**Crime:** Unexplained constants critical to performance.\n",
        "*Example: `learning_rate = 0.00137`.*\n",
        ":::\n",
        "::: {.column width=\"25%\"}\n",
        "![The Vague Preprocessing](images/mugshot_image.png){fig-align=\"center\" height=\"250\"}\n",
        "\n",
        "**Crime:** Hand-wavy descriptions of data preparation.\n",
        "*Example: \"...images were normalized...\"*\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.column width=\"25%\"}\n",
        "![The Undocumented Trick](images/mugshot_rabbit.png){fig-align=\"center\" height=\"250\"}\n",
        "\n",
        "**Crime:** Crucial implementation details absent from the paper.\n",
        "*Example: Gradient clipping, specific weight initialization, filtering out detections in saturated areas.*\n",
        ":::\n",
        "::: {.column width=\"25%\"}\n",
        "![The Vague data](images/mugshot_film.png){fig-align=\"center\" height=\"250\"}\n",
        "\n",
        "**Crime:** Vague description of the training/evaluation data.\n",
        "*Example: vague data acquisition description.*\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## A Checklist for Clarity {.smaller}\n",
        "\n",
        "A paper that perfectly describes its method is resilient and trustworthy. Here’s how to write one.\n",
        "\n",
        "- [ ] **Justify constants:** If a number isn't obvious, explain its origin (e.g., \"from an empirical sweep,\" \"as in Smith et al., 2025\").\n",
        "\n",
        "- [ ] **Document all steps and pre/post-processing:** Give the equation for normalization (`(x - mean) / std`) and the exact values used. Name the filter and its parameters. Publish a hyperparameter table.\n",
        "\n",
        "- [ ] **Use Pseudocode:** For any complex algorithm or training loop, provide clear pseudocode. It is the ultimate bridge between theory and code.\n",
        "\n",
        "- [ ] **Specify data**: Explicitly describe which data you use, in which way. If you acquire data for the paper, follow reproducibility practices for data.\n",
        "\n",
        "\n",
        "##  A Checklist for Clarity\n",
        "::: {.callout-tip icon=\"true\"}\n",
        "## A Gold Standard\n",
        "\n",
        "Journals like **IPOL (Image Processing On Line)** are built on algorithmic reproducibility. The implementation and article are peer-reviewed side-by-side to ensure the article details the method well-enough that it could be re-implemented from scratch. This guarantees the method's preservation and validity.\n",
        ":::\n",
        "<embed src=\"ipol_article.pdf\" width=\"100%\" height=\"800\" type=\"application/pdf\">\n",
        "\n",
        "##  A Checklist for Clarity\n",
        "::: {.callout-tip icon=\"true\"}\n",
        "## A Gold Standard\n",
        "\n",
        "Journals like **IPOL (Image Processing On Line)** are built on algorithmic reproducibility. The implementation and article are peer-reviewed side-by-side to ensure the article details the method well-enough that it could be re-implemented from scratch. This guarantees the method's preservation and validity.\n",
        ":::\n",
        "<iframe src=\"https://ipolcore.ipol.im/demo/clientApp/demo.html?id=420&archive=791228\" width=\"100%\" height=\"800px\" style=\"border:none; display:block; margin:0 auto; background-color:white\"></iframe>\n",
        "\n",
        "\n",
        "# From zero to Reproducible\n",
        "\n",
        "## Starting Point: The Research Notebook\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"60%\"}\n",
        "- ✅ Rapid exploration & prototyping\n",
        "- ✅ Easy visualization\n",
        "- ❌ Non-linear execution hides the true workflow\n",
        "- ❌ \"Hidden state\" makes results hard to trust\n",
        "- ❌ Impossible to use as a simple tool\n",
        "\n",
        "### How do we turn this sketch into a reliable tool?\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "[Prompt: A screenshot of a very long and messy Jupyter Notebook with out-of-order cell execution numbers.](images/messy_notebook.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Level 1: Scripts & A Blueprint\n",
        "\n",
        "The first step is to create a clear, reusable structure.\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"30%\"}\n",
        "\n",
        "![Blueprint](images/diagram_blueprint.svg){fig-align=\"center\"}\n",
        ":::\n",
        "::: {.column width=\"70%\"}\n",
        "### Checklist for a Good Structure\n",
        "- **Clear instructions:** A `README.md` explaining setup and execution.\n",
        "- Separate scripts to retrain the model, reproduce benchmark results, and use the model.\n",
        "- **Provide pre-trained Models:** Don't force users to retrain everything.\n",
        ":::\n",
        "::::\n",
        "---\n",
        "\n",
        "## Level 2: The Basic Parts List\n",
        "\n",
        "Your code can't run in a vacuum. You must specify all its dependencies with **pinned versions**.\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"28%\"}\n",
        "**❌**\n",
        "```txt\n",
        "# requirements.txt\n",
        "numpy\n",
        "torch\n",
        "```\n",
        ":::\n",
        "::: {.column width=\"28%\"}\n",
        "**❌**\n",
        "```txt\n",
        "# requirements.txt\n",
        "numpy\n",
        "torch\n",
        "tqdm\n",
        "pillow\n",
        "imageio\n",
        "```\n",
        ":::\n",
        "::: {.column width=\"39%\"}\n",
        "**✅**\n",
        "```txt\n",
        "# requirements.txt\n",
        "numpy==1.26.4\n",
        "torch==2.4.1\n",
        "tqdm==4.4.1\n",
        "pillow=11.3.0\n",
        "imageio==2.37.0\n",
        "```\n",
        ":::\n",
        "::::\n",
        "\n",
        "**But:** a `requirements.txt` doesn't lock the dependencies *of your dependencies*. Results can still vary.\n",
        "\n",
        "---\n",
        "\n",
        "## Level 3: The Complete Bill of Materials\n",
        "\n",
        "::: {.incremental}\n",
        "- **Solution:** Lock the *entire* environment with modern tools.\n",
        "- **Our Choice:** **`uv`**.\n",
        "- **Why?** It's incredibly fast, all-in-one (installer, venv manager), and creates a perfect, reproducible lock file.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Hands-On: A Perfect Python Environment\n",
        "\n",
        "::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "#### 1. For the Author\n",
        "\n",
        "```bash\n",
        "# Initialize a new project\n",
        "$ uv init\n",
        "\n",
        "# Pin a Python version\n",
        "$ uv python pin 3.11\n",
        "\n",
        "# Add packages to pyproject.toml\n",
        "# and generate a uv.lock file\n",
        "$ uv add numpy==1.26.4 torch\n",
        "```\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "#### 2. For the User\n",
        "\n",
        "```bash\n",
        "# Clone the repository\n",
        "$ git clone ...\n",
        "\n",
        "# Install the EXACT environment\n",
        "# from the uv.lock file\n",
        "$ uv sync\n",
        "\n",
        "# Run the code\n",
        "$ uv run predict.py  # equivalent to uv run python predict.py\n",
        "$ uv run my_executable\n",
        "```\n",
        ":::\n",
        ":::\n",
        "\n",
        "Use `uv` from the beginning, even when experimenting and developing!\n",
        "\n",
        "To use libraries without packaging them in the final environment (e. g. Jupyter notebooks):\n",
        "```bash\n",
        "$ uv run --with jupyter --with matplotlib jupyter lab \n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## When Python Isn't Enough...\n",
        "\n",
        "What about dependencies on the operating system itself?\n",
        "\n",
        "![The dependency iceberg](images/diagram_iceberg.svg){fig-align=\"center\"}\n",
        "\n",
        "---\n",
        "\n",
        "## Level 4: The 'Computer in a File'\n",
        "\n",
        "**Solution:** A **Container** (like Docker) packages everything:\n",
        "Code + Python Environment + OS Libraries.\n",
        "\n",
        "### Hands-On: The `Dockerfile` Recipe\n",
        "```dockerfile\n",
        "# Start from a specific Python base image\n",
        "FROM python:3.11-slim\n",
        "\n",
        "# Set working directory\n",
        "WORKDIR /app\n",
        "\n",
        "# Install uv\n",
        "RUN pip install uv\n",
        "\n",
        "# Copy ONLY the lock files\n",
        "COPY pyproject.toml uv.lock ./\n",
        "\n",
        "# Install the exact Python env\n",
        "RUN uv sync --no-cache\n",
        "\n",
        "# Copy the rest of your code\n",
        "COPY . .\n",
        "\n",
        "# Define a default command\n",
        "CMD [\"uv\", \"run\", \"python\", \"predict.py\"]\n",
        "```\n",
        "Now anyone with Docker can run your code, identically, *everywhere*.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary: Climbing the Ladder\n",
        "\n",
        "![Ladder](images/diagram_ladder.svg){fig-align=\"center\"}\n",
        "\n",
        "Even with a perfect container, some challenges remain...\n",
        "\n",
        "---\n",
        "\n",
        "## The CUDA Challenge\n",
        "\n",
        "**The Problem:** A dependency matrix of Hardware → Driver → Toolkit → Library.\n",
        "\n",
        "::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "#### Solution Part 1: Inside the Container\n",
        "Use NVIDIA's official base images in your `Dockerfile` to lock the CUDA Toolkit.\n",
        "\n",
        "```dockerfile\n",
        "FROM nvidia/cuda:12.6.1-cudnn-devel-ubuntu22.04\n",
        "...\n",
        "```\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "#### Solution Part 2: On the Host\n",
        "The user needs the NVIDIA Container Toolkit and a sufficiently new driver.\n",
        "\n",
        "**Your Job:** Be explicit! State the required driver version in your `README.md`.\n",
        ":::\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Remaining Obstacles: Data & Hardware\n",
        "\n",
        "::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "### The Data Barrier\n",
        "- **Size:** Provide download scripts; use DVC.\n",
        "- **Access:** Offer a \"demo mode\" with public/synthetic data.\n",
        "- **Format:** Document precisely and provide conversion scripts.\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "### The Hardware Chasm\n",
        "- **CPU (x86/ARM):** Provide multi-arch Docker builds.\n",
        "- **RAM/Resources:** Document minimum requirements clearly.\n",
        ":::\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Remaining Obstacles: Software Dependencies\n",
        "\n",
        "::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "#### The Polyglot Project\n",
        "Your code might mix Python, C++, Rust, other libraries...\n",
        "\n",
        "![](images/languages.png)\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "#### The Solution\n",
        "- **Containerization is essential.** Your `Dockerfile` must install *all* required runtimes.\n",
        "- **Be transparent** about paid licenses (e.g., MATLAB) in your `README`.\n",
        ":::\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## The Final Mile: Usability\n",
        "\n",
        "Even if code is runnable, is it *usable*?\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "### Bad CLI\n",
        "\n",
        "**Problem:** A command line with dozens of obscure, undocumented flags is hostile to users.\n",
        "```bash\n",
        "# What do these even mean?!\n",
        "$ python run.py -a 0.1 -b 32 --z_dim 128 -fe_lr 0.00137\n",
        "```\n",
        "**Solution:** Use libraries like `Typer` or `Argparse` to create a clean, self-documenting CLI with help text.\n",
        "\n",
        "### No Samples\n",
        "\n",
        "**Problem:** A user clones your repository but has no correctly formatted data to test the `predict.py` script.\n",
        "\n",
        "**Solution:** Always include a `sample_data/` directory and a `run_demo.sh` script. A \"Quick Start\" that runs in seconds is invaluable.\n",
        "\n",
        "### No UI/Demo\n",
        "\n",
        "**Problem:** The command line is still a major barrier for many potential users (collaborators, industry, other fields).\n",
        "\n",
        "**Solution:** Wrapping your script in an online demo makes it universally accessible and dramatically increases its impact.\n",
        "\n",
        ":::\n",
        "\n",
        "# Creating a demo\n",
        "\n",
        "## Why Bother Making a Demo?\n",
        "\n",
        "A demo transforms your research from a static paper into a living tool.\n",
        "\n",
        "::: {.columns}\n",
        "::: {.column width=\"33%\"}\n",
        "#### 👁️\n",
        "#### Visibility & Impact\n",
        "Go beyond the PDF. A demo makes your work discoverable and understandable to a much wider audience.\n",
        ":::\n",
        "::: {.column width=\"33%\"}\n",
        "#### 💬\n",
        "#### Usability & Feedback\n",
        "Let people *use* your research. It's the fastest way to test replicability, get feedback, find bugs, and spark collaborations.\n",
        ":::\n",
        "::: {.column width=\"33%\"}\n",
        "#### ✅\n",
        "#### Proof of Work\n",
        "A working demo is the ultimate proof that your code isn't just theory. It runs, it works, and it builds trust.\n",
        ":::\n",
        ":::\n",
        "\n",
        "## Our demo target\n",
        "[Eloi Tanguy, Julie Delon, Nathaël Gozlan, «Un algorithme de point fixe pour calculer des barycentres robustes entre mesures».](https://github.com/eloitanguy/ot_bar)\n",
        "\n",
        "<embed src=\"article_label_reproductible.pdf\" width=\"100%\" height=\"800\" type=\"application/pdf\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Create a demo with Streamlit\n",
        "\n",
        "![](images/streamlit_logo.svg){width=100}\n",
        "\n",
        "- **What is it?** An open-source Python library to build and share web apps for machine learning and data science.\n",
        "\n",
        "- **Why Streamlit for this tutorial?**\n",
        "  - It's just a Python script. No HTML/CSS/JS required.\n",
        "  - It turns data scripts into shareable apps in minutes.\n",
        "  - The development workflow is fast and intuitive.\n",
        "\n",
        "---\n",
        "\n",
        "## Example 1: A Minimal Demo\n",
        "\n",
        "Here's how to wrap a function in a simple user interface.\n",
        "\n",
        "  [Live Demo](https://qbammey-r-example-demoexamplesoutlier-colour-transferapp-ymhhsf.streamlit.app)\n",
        "\n",
        "\n",
        "```python\n",
        "# app.py\n",
        "import io\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import run  # your run.py in the same folder\n",
        "\n",
        "st.set_page_config(page_title=\"OT Color Transfer (tutorial)\", layout=\"centered\")\n",
        "st.title(\"🎨 OT Color Transfer (tutorial)\")\n",
        "\n",
        "# uploads\n",
        "base_file = st.file_uploader(\"Base image (to stylize)\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "target_file = st.file_uploader(\"Target image (style source)\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "# parameters (defaults match run.py)\n",
        "col1, col2 = st.columns(2)\n",
        "with col1:\n",
        "    downscale = st.number_input(\"Downscale size\", min_value=8, max_value=256, value=50, step=1)\n",
        "    metric = st.selectbox(\"Metric\", [\"l2\", \"l1\"], index=0)\n",
        "with col2:\n",
        "    reg = st.number_input(\"Entropic reg (0 = EMD)\", min_value=0.0, value=0.0, step=0.01, format=\"%.4f\")\n",
        "    sinkhorn_max_iter = st.number_input(\"Sinkhorn max iters\", min_value=100, max_value=20000, value=1000, step=100)\n",
        "\n",
        "run_btn = st.button(\"Run\")\n",
        "\n",
        "if run_btn:\n",
        "    if base_file is None or target_file is None:\n",
        "        st.warning(\"Please upload both images.\")\n",
        "    else:\n",
        "        # load to [0,1] float RGB\n",
        "        base_img = np.asarray(Image.open(base_file).convert(\"RGB\"), dtype=np.float64) / 255.0\n",
        "        target_img = np.asarray(Image.open(target_file).convert(\"RGB\"), dtype=np.float64) / 255.0\n",
        "\n",
        "        styl = run.color_transfer_ot(\n",
        "            base_img=base_img,\n",
        "            target_img=target_img,\n",
        "            downscale=int(downscale),\n",
        "            metric=metric,\n",
        "            reg=float(reg),\n",
        "            sinkhorn_max_iter=int(sinkhorn_max_iter),\n",
        "        )\n",
        "\n",
        "        st.subheader(\"Result\")\n",
        "        st.image(styl, use_container_width=True)\n",
        "\n",
        "        # quick download\n",
        "        buf = io.BytesIO()\n",
        "        Image.fromarray((np.clip(styl, 0, 1) * 255).astype(np.uint8)).save(buf, format=\"PNG\")\n",
        "        st.download_button(\"Download PNG\", data=buf.getvalue(), file_name=\"stylized.png\", mime=\"image/png\")\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Deploying Your Demo\n",
        "\n",
        "Locally : `uv run streamlit run app.py` (or, without `uv`, `streamlit run app.py`)\n",
        "\n",
        "Making your app public is also easy and free with Streamlit Community Cloud.\n",
        "\n",
        "**Key Steps:**\n",
        "\n",
        "1.  Put your app, `pyproject.toml`, `uv.lock`, and a `packages.txt` file in a public GitHub repo.\n",
        "2.  In Streamlit Cloud, link your repo.\n",
        "3.  Point to your main file path (e.g., `demo/app.py`).\n",
        "4.  Click Deploy!\n",
        "\n",
        "---\n",
        "\n",
        "## How Far Can You Go? A Polished App\n",
        "\n",
        "With a bit more code, a simple demo can become a polished application with caching, state management, and a better layout.\n",
        "\n",
        "[Live demo](https://example-demoexamplesoutlier-colou-dq04w1.streamlit.app/)\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "import io\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Import your research function ---\n",
        "import run\n",
        "\n",
        "# --- Define the directory of the current script to find example images ---\n",
        "# This is the key to making file paths robust. `Path(__file__)` gets the path\n",
        "# to this .py file, and `.parent` gets the directory it's in.\n",
        "SCRIPT_DIR = Path(__file__).parent\n",
        "\n",
        "# --- Page Configuration ---\n",
        "st.set_page_config(\n",
        "    page_title=\"OT Color Transfer (Advanced)\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# --- Caching the Core Function ---\n",
        "@st.cache_data\n",
        "def cached_color_transfer(base_img_bytes, target_img_bytes, downscale, metric, reg, sinkhorn_max_iter):\n",
        "    \"\"\"\n",
        "    A wrapper around the core function to make it cacheable.\n",
        "    We pass image bytes instead of numpy arrays because arrays are not hashable.\n",
        "    \"\"\"\n",
        "    base_img = np.asarray(Image.open(io.BytesIO(base_img_bytes)).convert(\"RGB\"), dtype=np.float64) / 255.0\n",
        "    target_img = np.asarray(Image.open(io.BytesIO(target_img_bytes)).convert(\"RGB\"), dtype=np.float64) / 255.0\n",
        "    \n",
        "    return run.color_transfer_ot(\n",
        "        base_img=base_img,\n",
        "        target_img=target_img,\n",
        "        downscale=int(downscale),\n",
        "        metric=metric,\n",
        "        reg=float(reg),\n",
        "        sinkhorn_max_iter=int(sinkhorn_max_iter),\n",
        "    )\n",
        "\n",
        "# --- Helper function to load example images using pathlib ---\n",
        "def load_example_image(image_filename):\n",
        "    \"\"\"Loads an image from a path relative to the script's directory.\"\"\"\n",
        "    # Construct the full, absolute path to the image\n",
        "    image_path = SCRIPT_DIR / image_filename\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return f.read()\n",
        "\n",
        "# --- Main App UI ---\n",
        "st.title(\"🎨 Advanced OT Color Transfer\")\n",
        "st.write(\"This demo showcases a more robust Streamlit app with caching, state management, and error handling.\")\n",
        "\n",
        "# --- Sidebar for Inputs and Parameters ---\n",
        "with st.sidebar:\n",
        "    st.header(\"Inputs\")\n",
        "    \n",
        "    # 2. Update the example options with your filenames and names\n",
        "    example_options = {\n",
        "        \"Example 1\": (\"B2.jpg\", \"A1.jpg\"),\n",
        "        \"Example 2\": (\"B2.jpg\", \"C1.jpg\"),\n",
        "    }\n",
        "    \n",
        "    source_type = st.radio(\"Choose image source:\", [\"Upload your own\", \"Use an example\"], index=1) # Default to example\n",
        "\n",
        "    if source_type == \"Upload your own\":\n",
        "        base_file = st.file_uploader(\"Base image (to stylize)\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "        target_file = st.file_uploader(\"Target image (style source)\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "    else:\n",
        "        selected_example = st.selectbox(\"Select an example:\", list(example_options.keys()))\n",
        "        base_filename, target_filename = example_options[selected_example]\n",
        "        # Use our robust helper function to load the images\n",
        "        base_file = load_example_image(base_filename)\n",
        "        target_file = load_example_image(target_filename)\n",
        "\n",
        "    st.header(\"Parameters\")\n",
        "    with st.expander(\"Algorithm Controls\", expanded=True):\n",
        "        downscale = st.number_input(\"Downscale size\", 8, 256, 50, 1)\n",
        "        metric = st.selectbox(\"Metric\", [\"l2\", \"l1\"], 0)\n",
        "        reg = st.number_input(\"Entropic reg (0 = EMD)\", 0.0, 1.0, 0.0, 0.01, format=\"%.4f\")\n",
        "        if reg > 0:\n",
        "            sinkhorn_max_iter = st.number_input(\"Sinkhorn max iters\", 100, 20000, 1000, 100)\n",
        "        else:\n",
        "            sinkhorn_max_iter = 1000\n",
        "\n",
        "    run_btn = st.button(\"Run Style Transfer\", type=\"primary\")\n",
        "\n",
        "# --- Main Area for Displaying Images ---\n",
        "col1, col2 = st.columns(2)\n",
        "if base_file is not None:\n",
        "    col1.image(base_file, caption=\"Base Image\", use_container_width=True)\n",
        "if target_file is not None:\n",
        "    col2.image(target_file, caption=\"Target Style\", use_container_width=True)\n",
        "    \n",
        "if run_btn:\n",
        "    if base_file is None or target_file is None:\n",
        "        st.warning(\"Please provide both a base and a target image.\")\n",
        "    else:\n",
        "        base_bytes = base_file.getvalue() if hasattr(base_file, 'getvalue') else base_file\n",
        "        target_bytes = target_file.getvalue() if hasattr(target_file, 'getvalue') else target_file\n",
        "        \n",
        "        with st.spinner('Stylizing image... this may take a moment.'):\n",
        "            try:\n",
        "                stylized_image = cached_color_transfer(\n",
        "                    base_bytes, target_bytes, downscale, metric, reg, sinkhorn_max_iter\n",
        "                )\n",
        "                st.session_state['last_result'] = stylized_image\n",
        "            except Exception as e:\n",
        "                st.error(f\"An error occurred during processing: {e}\")\n",
        "                if 'last_result' in st.session_state:\n",
        "                    del st.session_state['last_result']\n",
        "\n",
        "if 'last_result' in st.session_state:\n",
        "    st.divider()\n",
        "    st.header(\"Result\")\n",
        "    result_image = st.session_state['last_result']\n",
        "    st.image(result_image, caption=\"Stylized Result\", use_column_width=True)\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    Image.fromarray((np.clip(result_image, 0, 1) * 255).astype(np.uint8)).save(buf, format=\"PNG\")\n",
        "    st.download_button(\n",
        "        \"Download Result\",\n",
        "        data=buf.getvalue(),\n",
        "        file_name=\"stylized_result.png\",\n",
        "        mime=\"image/png\"\n",
        "    )\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Alternatives to Streamlit\n",
        "\n",
        "Streamlit is great, but other tools might be better for specific needs.\n",
        "\n",
        "::: {.columns}\n",
        "::: {.column width=\"33%\"}\n",
        "![](images/gradio_logo.svg){width=100}\n",
        "\n",
        "Simple, but lacks flexibility. Best for pure ML models, Hugging Face spaces.\n",
        ":::\n",
        "::: {.column width=\"33%\"}\n",
        "![](images/shiny_logo.png){width=150}\n",
        "\n",
        "More complex, more versatility. Best if some interactivity (partial reruns) is needed.\n",
        "\n",
        ":::\n",
        "::: {.column width=\"33%\"}\n",
        "![](images/plotly_logo.png){width=150}\n",
        "\n",
        "Even more complex, excellent versatility within the Plotly environment.\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Towards full reproducibility\n",
        "\n",
        "* Image Processing On Line (IPOL) is a **journal** and **demo system**\n",
        "* Submissions to IPOL are tripartite:\n",
        "    * an article containing a complete description (with pseudo-code) of the implementation, and enabling its reconstruction from scratch\n",
        "    * an implementation, that is peer-reviewed to assert that it matches the article\n",
        "    * an online demo\n",
        "\n",
        "## IPOL demo: a Dockerfile\n",
        "\n",
        "```dockerfile\n",
        "FROM registry.ipol.im/ipol:v2-py3.11\n",
        "COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/\n",
        "\n",
        "# Copy the code to $bin\n",
        "ENV bin /workdir/bin/\n",
        "RUN mkdir -p $bin\n",
        "WORKDIR $bin\n",
        "COPY . .\n",
        "\n",
        "# sync dependencies\n",
        "RUN uv sync\n",
        "\n",
        "# the execution will happen in the folder /workdir/exec\n",
        "# it will be created by IPOL\n",
        "\n",
        "# some QoL tweaks\n",
        "ENV PYTHONDONTWRITEBYTECODE 1\n",
        "ENV PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION python\n",
        "ENV PATH $bin:$PATH\n",
        "\n",
        "# $HOME is writable by the user `ipol`, but \n",
        "ENV HOME /home/ipol\n",
        "# chmod 777 so that any user can use the HOME, in case the docker is run with -u 1001:1001\n",
        "RUN groupadd -g 1000 ipol && useradd -m -u 1000 -g 1000 ipol -d $HOME && chmod -R 777 $HOME\n",
        "USER ipol\n",
        "```\n",
        "\n",
        "## IPOL demo: a JSON description\n",
        "```json \n",
        "{\n",
        "    \"general\": {\n",
        "        \"demo_title\": \"Gretsi 2025 Ipol demo: OT colour transfer\",\n",
        "        \"requirements\": \"docker\"\n",
        "    },\n",
        "    \"build\": {\n",
        "      \"url\": \"git@github.com:qbammey/reproducible_research_gretsi.git\",\n",
        "      \"rev\": \"origin/main\",\n",
        "      \"dockerfile\": \"Dockerfile\"\n",
        "   },\n",
        "   \"inputs\": [\n",
        "      {\n",
        "         \"type\": \"image\",\n",
        "         \"description\": \"Base image to stylize.\",\n",
        "         \"max_pixels\": \"1024*1024\",\n",
        "         \"dtype\": \"3x8i\",\n",
        "         \"ext\": \".png\"\n",
        "      },\n",
        "      {\n",
        "         \"type\": \"image\",\n",
        "         \"description\": \"Style target\",\n",
        "         \"max_pixels\": \"1024*1024\",\n",
        "         \"dtype\": \"3x8i\",\n",
        "         \"ext\": \".png\"\n",
        "      }\n",
        "   ],\n",
        "   \"params\": [\n",
        "      {\n",
        "         \"id\": \"downscale\",\n",
        "         \"description\": \"Downscale level\",\n",
        "         \"label\": \"Lower:faster, higher:finer\",\n",
        "         \"type\": \"numeric\",\n",
        "         \"values\": {\n",
        "            \"min\": 5,\n",
        "            \"max\": 50,\n",
        "            \"default\": 30\n",
        "         }\n",
        "      },\n",
        "      {\n",
        "         \"id\": \"metric\",\n",
        "         \"description\": \"Metric to use\",\n",
        "         \"label\": \"Use L1 for outlier robustness\",\n",
        "         \"type\": \"selection_radio\",\n",
        "         \"values\": {\n",
        "            \"L1\": \"l1\",\n",
        "            \"L2\": \"l2\"\n",
        "         },\n",
        "         \"default_value\": \"l2\"\n",
        "      },\n",
        "      {\n",
        "         \"id\": \"reg\",\n",
        "         \"description\": \"Regularization\",\n",
        "         \"label\": \"Entropic regularization for Sinkhorn. Set 0.0 to use EMD (original behaviour), >0 for faster/smoother transport on larger problems\",\n",
        "         \"type\": \"range\",\n",
        "         \"values\": {\n",
        "            \"min\": 0,\n",
        "            \"max\": 0.1,\n",
        "            \"step\": 0.005,\n",
        "            \"default\": 0\n",
        "         }\n",
        "      },\n",
        "      {\n",
        "         \"id\": \"smi\",\n",
        "         \"description\": \"Synkhorn max iterations\",\n",
        "         \"type\": \"numeric\",\n",
        "         \"values\": {\n",
        "            \"min\": 200,\n",
        "            \"max\": 1000,\n",
        "            \"default\": 1000\n",
        "         },\n",
        "         \"visible\": \"(params.reg>0.001)\"\n",
        "      }\n",
        "   ],\n",
        "   \"run\": \"uv --project $bin run $bin/example_demo/examples/outlier_colour_transfer/run.py --base $input_0 --target $input_1 --output out.png --downscale $downscale --metric $metric --reg $reg --sinkhorn-max-iter $smi\",\n",
        "   \"results\": [\n",
        "      {\n",
        "         \"type\": \"gallery\",\n",
        "         \"contents\": {\n",
        "            \"Base image\": {\n",
        "               \"img\": \"input_0.png\"\n",
        "            },\n",
        "            \"Style target\": {\n",
        "               \"img\": \"input_1.png\"\n",
        "            },\n",
        "            \"Result\": {\n",
        "               \"img\": \"out.png\"\n",
        "            }\n",
        "         }\n",
        "      },\n",
        "       {\n",
        "         \"contents\": \"stdout.txt\",\n",
        "         \"label\": \"<p>Output</p>\",\n",
        "         \"type\": \"text_file\"\n",
        "      }\n",
        "   ],\n",
        "   \"archive\": {\n",
        "       \"archive_always\": true,\n",
        "      \"enable_reconstruct\": true,\n",
        "      \"files\": {\n",
        "         \"input_0.png\": \"Base image\",\n",
        "         \"input_1.png\": \"Style target\",\n",
        "         \"out.png\": \"Result\"\n",
        "      },\n",
        "      \"params\": [\n",
        "         \"downscale\",\n",
        "         \"metric\",\n",
        "         \"reg\",\n",
        "         \"smi\"\n",
        "      ]\n",
        "   }\n",
        "}\n",
        "```\n",
        "\n",
        "## IPOL demo\n",
        "\n",
        "<iframe src=\"https://ipolcore.ipol.im/demo/clientApp/demo.html?id=77777000513&archive=791279\" width=\"100%\" height=\"600px\" style=\"border:none; display:block; margin:0 auto; background-color:white\"></iframe>\n",
        "\n",
        "# Conclusion {visibility=\"hidden\"}\n",
        "\n",
        "## To conclude\n",
        "\n",
        "* Designing clean, reproducible, and easy-to-use implementations helps **build trust** and **maximize your impact**.\n",
        "* Small cost up-front, will save you (and others) lots of time\n",
        "* Once the code is well-packaged with clear dependencies, easy to turn into a demo\n",
        "* Still some obstacles such as hardware dependencies, but this is getting better.\n",
        "* Beyond implementation reproducibility: algorithm reproducibility is essential to trust what the code does (e. g. IPOL article)"
      ],
      "id": "e8c67c4d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}